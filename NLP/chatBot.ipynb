{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcd8 Meteor Chatbot \u2014 Jupyter-Friendly Version\n",
    "\n",
    "This notebook implements a simple NLP chatbot named **Meteor Bot**. It uses **NLTK**, **TF-IDF**, and **cosine similarity** to return relevant responses to user queries based on two corpora: one for general answers and another for module-related questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "We start by importing necessary libraries including NLTK for natural language processing,\n",
    "Scikit-learn for TF-IDF and cosine similarity, and standard Python libraries for basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd27 Setup and Imports\n",
    "import warnings, random, string\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Required NLTK Resources\n",
    "We download the Punkt tokenizer and WordNet lemmatizer to assist in tokenization and normalization of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udeab Disable Warnings and Download NLTK Resources\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Data Files\n",
    "Ensure that `answer.txt` and `chatbot.txt` are placed in the same directory as this notebook. These files\n",
    "contain the corpora that the chatbot will use for answering questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udcc2 Load Required Files\n",
    "DATA_DIR = Path(\".\")\n",
    "ANS_FILE = DATA_DIR / \"answer.txt\"\n",
    "Q_FILE = DATA_DIR / \"chatbot.txt\"\n",
    "\n",
    "if not ANS_FILE.exists() or not Q_FILE.exists():\n",
    "    raise FileNotFoundError(\"\u274c  Put 'answer.txt' and 'chatbot.txt' in the same directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tokenize Text into Sentences\n",
    "We split the raw content of each file into individual sentences so that responses can be matched at the sentence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udcd6 Tokenize the Corpora\n",
    "raw_ans = ANS_FILE.read_text(encoding=\"utf8\", errors=\"ignore\").lower()\n",
    "raw_q = Q_FILE.read_text(encoding=\"utf8\", errors=\"ignore\").lower()\n",
    "\n",
    "sent_tokens_ans = nltk.sent_tokenize(raw_ans)\n",
    "sent_tokens_q = nltk.sent_tokenize(raw_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Text Normalization Helpers\n",
    "Functions to remove punctuation, tokenize, and lemmatize user input and corpus content for consistent comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83e\udde0 NLP Helpers: Lemmatizer and Normalizer\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "remove_punct = dict((ord(p), None) for p in string.punctuation)\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(t) for t in tokens]\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Handle Greetings and Predefined Replies\n",
    "This section defines how the bot should handle basic greetings and common small talk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udcac Greeting Detection and Predefined Replies\n",
    "INTRO_ANS = [\n",
    "    \"My name is Meteor Bot.\",\n",
    "    \"You can call me Meteor Bot or B.O.T.\",\n",
    "    \"I'm Meteor Bot, happy to chat!\"\n",
    "]\n",
    "GREETING_IN = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
    "GREETING_OUT = (\"hi\", \"hey\", \"hello\", \"hi there\", \"hello there\")\n",
    "\n",
    "def greeting(sentence: str):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_IN:\n",
    "            return random.choice(GREETING_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Core Logic - TF-IDF Based Response Matching\n",
    "We use TF-IDF to vectorize the text and cosine similarity to find the most relevant response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83e\udd16 TF-IDF Based Response Generator\n",
    "def generate_response(user_msg: str, corpus):\n",
    "    corpus.append(user_msg)\n",
    "    vec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=None)\n",
    "    tfidf = vec.fit_transform(corpus)\n",
    "    sims = cosine_similarity(tfidf[-1], tfidf)\n",
    "\n",
    "    idx = sims.argsort()[0][-2]\n",
    "    flat = sims.flatten(); flat.sort()\n",
    "    score = flat[-2]\n",
    "    corpus.pop()\n",
    "\n",
    "    if score == 0:\n",
    "        return \"I'm sorry, I didn't understand that.\"\n",
    "    return corpus[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Chatbot Interface Function\n",
    "This function integrates canned responses and TF-IDF matching logic to respond to user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83c\udfaf Public Chat Interface\n",
    "def chat(user_msg: str) -> str:\n",
    "    u = user_msg.strip().lower()\n",
    "    if not u:\n",
    "        return \"Please say something \ud83d\ude42\"\n",
    "\n",
    "    if u in (\"bye\", \"goodbye\", \"see you\"):\n",
    "        return \"Bye! Take care.\"\n",
    "    if u in (\"thanks\", \"thank you\", \"thx\"):\n",
    "        return \"You're welcome.\"\n",
    "    if u in (\"how are you\", \"how r u\", \"how're you\", \"how's it going\", \"how's everything\"):\n",
    "        return \"I'm fine, thank you for asking!\"\n",
    "    if \"your name\" in u:\n",
    "        return random.choice(INTRO_ANS)\n",
    "\n",
    "    g = greeting(u)\n",
    "    if g:\n",
    "        return g\n",
    "\n",
    "    if \"module\" in u:\n",
    "        return generate_response(u, sent_tokens_q.copy())\n",
    "\n",
    "    return generate_response(u, sent_tokens_ans.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Command-Line Style Chat (Optional)\n",
    "This allows you to chat with the bot directly from the notebook using standard input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udcbb Run Terminal-style Chat in Notebook\n",
    "def run_cli():\n",
    "    print(\"Meteor Bot \u2014 type 'bye' to quit\")\n",
    "    while True:\n",
    "        try:\n",
    "            user = input(\"You: \").strip()\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            print(\"\\nBye!\")\n",
    "            break\n",
    "        if not user:\n",
    "            continue\n",
    "        reply = chat(user)\n",
    "        print(\"Bot:\", reply)\n",
    "        if user.lower() in (\"bye\", \"goodbye\", \"see you\"):\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}