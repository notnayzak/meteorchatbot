{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51719395",
   "metadata": {},
   "source": [
    "# Meteor ChatBot\n",
    "\n",
    "Welcome! This notebook walks you through building a simple chatbot using Python. It’s called **Meteor Bot**, and it can respond to basic greetings, questions about Python, and even look up answers from a text corpus using natural language processing.\n",
    "\n",
    "We’ll be using tools like **NLTK** for language processing and **scikit-learn** for comparing the meaning of text with TF-IDF and cosine similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980fac3",
   "metadata": {},
   "source": [
    "## Imports and Warnings\n",
    "We import necessary libraries including:\n",
    "- `nltk` for NLP tasks\n",
    "- `sklearn` for TF-IDF and similarity\n",
    "- `warnings` to suppress warnings\n",
    "- `random`, `string`, and `numpy` for helper operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e904212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686da3f3",
   "metadata": {},
   "source": [
    "## NLTK Data\n",
    "We download the `punkt` tokenizer for sentence splitting and the `wordnet` lemmatizer to reduce words to their base forms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e161a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nayzak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nayzak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd762fa",
   "metadata": {},
   "source": [
    "## Load and Tokenize Text\n",
    "- Two external text files (`answer.txt`, `chatbot.txt`) are loaded.\n",
    "- The content is lowercased and tokenized into sentences.\n",
    "- We set up a lemmatizer and a normalization function to process user input consistently by removing punctuation and reducing words to their base form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3bdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess text files\n",
    "with open('answer.txt', 'r', errors='ignore') as f:\n",
    "    raw = f.read().lower()\n",
    "with open('chatbot.txt', 'r', errors='ignore') as m:\n",
    "    rawone = m.read().lower()\n",
    "\n",
    "# Tokenize\n",
    "sent_tokens = nltk.sent_tokenize(raw)\n",
    "sent_tokensone = nltk.sent_tokenize(rawone)\n",
    "\n",
    "# Lemmatization setup\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ec31b",
   "metadata": {},
   "source": [
    "## Predefined Responses and Categories\n",
    "We define:\n",
    "- Static responses for greetings, introductions, and basic questions.\n",
    "- Several helper functions to match specific queries like greetings or \"what is Python?\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c958edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Introduce_Ans = [\n",
    "    \"My name is Meteor Bot.\",\n",
    "    \"You can call me Meteor Bot or B.O.T.\",\n",
    "    \"I'm Meteor Bot, happy to chat!\",\n",
    "]\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"hello\", \"hi there\", \"hello there\"]\n",
    "Basic_Q = (\"what is python\", \"what is python?\")\n",
    "Basic_Ans = \"Python is a high-level, interpreted programming language.\"\n",
    "Basic_Om = (\n",
    "    \"what is module\", \"what is module?\", \"what is module in python\", \"what is module in python?\"\n",
    ")\n",
    "Basic_AnsM = [\n",
    "    \"A module is a file containing Python code, like functions and classes.\",\n",
    "    \"Modules help organize and reuse code.\",\n",
    "    \"Think of a module as a toolbox for Python functions.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba2e93",
   "metadata": {},
   "source": [
    "## Generate a Response using TF-IDF\n",
    "When a user input doesn't match predefined questions:\n",
    "- We use TF-IDF to vectorize the input and the text corpus.\n",
    "- Cosine similarity is calculated between the input and the corpus.\n",
    "- The sentence with the highest similarity (if above a threshold) is returned.\n",
    "- Otherwise, a fallback message is shown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613f99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "\n",
    "def basic(sentence):\n",
    "    if sentence.lower() in Basic_Q:\n",
    "        return Basic_Ans\n",
    "\n",
    "def basicM(sentence):\n",
    "    if sentence.lower() in Basic_Om:\n",
    "        return random.choice(Basic_AnsM)\n",
    "\n",
    "def IntroduceMe(sentence):\n",
    "    return random.choice(Introduce_Ans)\n",
    "\n",
    "def generate_response(user_response, corpus):\n",
    "    meteor_response = ''\n",
    "    corpus.append(user_response)\n",
    "    vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words=None)\n",
    "    tfidf = vectorizer.fit_transform(corpus)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if req_tfidf == 0:\n",
    "        meteor_response += \"I'm sorry, I didn't understand that.\"\n",
    "    else:\n",
    "        meteor_response += corpus[idx]\n",
    "    corpus.pop()\n",
    "    return meteor_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b9ebb",
   "metadata": {},
   "source": [
    "## Chat Interface\n",
    "The main `chat()` function routes the user input:\n",
    "- If it's a known phrase like \"bye\" or \"thanks\", it responds directly.\n",
    "- If it includes keywords like \"module\", it uses a different corpus (`chatbot.txt`).\n",
    "- For everything else, it attempts a TF-IDF match from `answer.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5332b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chat(user_response):\n",
    "    user_response = user_response.lower()\n",
    "\n",
    "    if user_response == 'bye':\n",
    "        return \"Bye! Take care.\"\n",
    "\n",
    "    if user_response in ['thanks', 'thank you' , 'ty', 'thx']:\n",
    "        return \"You're welcome.\"\n",
    "\n",
    "    if user_response in [\"how are you\", \"how r u\", \"how're you\", \"how are ya\", \"how's it going\", \"how's everything\"]:\n",
    "        return \"I'm fine, thank you for asking!\"\n",
    "\n",
    "    if greeting(user_response):\n",
    "        return greeting(user_response)\n",
    "\n",
    "    if \"your name\" in user_response:\n",
    "        return IntroduceMe(user_response)\n",
    "\n",
    "    if basic(user_response):\n",
    "        return basic(user_response)\n",
    "\n",
    "    if basicM(user_response):\n",
    "        return basicM(user_response)\n",
    "\n",
    "    if \"module\" in user_response:\n",
    "        return generate_response(user_response, sent_tokensone)\n",
    "\n",
    "    return generate_response(user_response, sent_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da9d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: Type a message to chat with the bot\n",
    "# chat(\"hi\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
